{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled28.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSguAVDLFqDb",
        "outputId": "8fa27e47-640d-46ee-f8c0-1dca0304cce5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjGGI-djGFwM"
      },
      "source": [
        "#Importing the necesary packages\n",
        "import os\n",
        "from os import path\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3X8b6CmM5bl"
      },
      "source": [
        ""
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLe5vtpoJXzz",
        "outputId": "c045a96a-b6ae-441d-cc9c-612a2eb10cc7"
      },
      "source": [
        "PATH = '/content/drive/MyDrive/soft com lab/'\n",
        "os.listdir(PATH)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['training-a.csv',\n",
              " 'Matrix_Factorization_Assignment.csv',\n",
              " 'training-a',\n",
              " 'train_path']"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBSsHC6hXhK3"
      },
      "source": [
        "def showRawTrainingSamples(csv_filename):\n",
        "  df = pd.read_csv(PATH + csv_filename)\n",
        "  print(csv_filename)\n",
        "  print(df.columns)\n",
        "  return df"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcSzlU1PXj1W",
        "outputId": "5a231505-ac4e-44d6-dc99-ce92d226df46"
      },
      "source": [
        "a_csv = showRawTrainingSamples('training-a.csv')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training-a.csv\n",
            "Index(['filename', 'original filename', 'scanid', 'digit',\n",
            "       'database name original', 'contributing team', 'database name'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tad7NqRmGoL8"
      },
      "source": [
        ""
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfJNDklvKVtV"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgoFDIO6GOwP"
      },
      "source": [
        ""
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhsJUgm0GT3M"
      },
      "source": [
        "\n",
        "#here i make a function for taking filename and digit from csv file.\n",
        "def dropColumns(csv_file):\n",
        "  csv_file = csv_file[['filename', 'digit']]\n",
        "  print(csv_file)\n",
        "  print(csv_file.iloc[:5, :])   \n",
        "  print(\"=============================\")\n",
        "  return csv_file"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-E4dG_KIE_N",
        "outputId": "096c7d54-c8f6-4ebe-af56-deff8bffd7a3"
      },
      "source": [
        "a_csv = dropColumns(a_csv)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         filename  digit\n",
            "0      a00000.png      5\n",
            "1      a00001.png      3\n",
            "2      a00002.png      1\n",
            "3      a00003.png      7\n",
            "4      a00004.png      0\n",
            "...           ...    ...\n",
            "19697  a19697.png      4\n",
            "19698  a19698.png      3\n",
            "19699  a19699.png      8\n",
            "19700  a19700.png      3\n",
            "19701  a19701.png      8\n",
            "\n",
            "[19702 rows x 2 columns]\n",
            "     filename  digit\n",
            "0  a00000.png      5\n",
            "1  a00001.png      3\n",
            "2  a00002.png      1\n",
            "3  a00003.png      7\n",
            "4  a00004.png      0\n",
            "=============================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdSP5CVvJF9D"
      },
      "source": [
        "TRAIN_PATH='/content/drive/MyDrive/soft com lab/training-a'\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRVKgRKrJaG9"
      },
      "source": [
        ""
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4zmRh6HJlsj"
      },
      "source": [
        "def processImages(folder_name):\n",
        "    src = PATH + folder_name + '/'\n",
        "    dir_folders = os.listdir(src)\n",
        "    for dir_name in dir_folders:\n",
        "        file_name = os.path.join(src, dir_name)\n",
        "        if os.path.isfile(file_name):\n",
        "            shutil.copy(file_name, TRAIN_PATH)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kEDiJX6MG0l"
      },
      "source": [
        "class Dataset(Dataset):\n",
        "    def __init__(self, df, root, transform=None):\n",
        "        self.data = df\n",
        "        self.root = root\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        item = self.data.iloc[index]\n",
        "        \n",
        "        path = self.root + \"/\" + item[0]\n",
        "        image = Image.open(path).convert('L')\n",
        "        label = item[1]\n",
        "        \n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "            \n",
        "        return image, label"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0TxomKDMLOi",
        "outputId": "a20a08c8-d5f9-4ad8-d468-56b4465ac4eb"
      },
      "source": [
        "mean = [0.5,]\n",
        "std = [0.5, ]\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((28,28)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "        transforms.Resize((28,28)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "])\n",
        "\n",
        "train_data  = Dataset(a_csv, TRAIN_PATH, train_transform)\n",
        "test_data = Dataset(a_csv, TRAIN_PATH, test_transform)\n",
        "\n",
        "print(\"Trainig Samples: \",len(train_data))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainig Samples:  19702\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOUN0gxsMZcc",
        "outputId": "e9778a03-bba7-4bd7-c287-241bcd764b5f"
      },
      "source": [
        "# Hyperparameters\n",
        "\n",
        "batch_size = 200\n",
        "num_iters = 2000\n",
        "input_dim = 28*28 # num_features = 784\n",
        "num_hidden = 100 # num of hidden nodes\n",
        "output_dim = 10\n",
        "\n",
        "learning_rate = 0.001  # More power so we can learn faster! previously it was 0.001\n",
        "\n",
        "num_epochs = num_iters / (len(train_data) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "print(num_epochs)\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJ1lg4ZSMdm6",
        "outputId": "f1d96d02-6dd3-498f-f7be-97dbd2bda7ab"
      },
      "source": [
        "# split data 10% for testing\n",
        "test_size = 0.2\n",
        "\n",
        "# obtain training indices that will be used for validation\n",
        "num_train = len(train_data)\n",
        "\n",
        "# mix data\n",
        "# index of num of train\n",
        "indices = list(range(num_train))\n",
        "# random the index\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(test_size * num_train))\n",
        "# divied into two part\n",
        "train_idx, test_idx = indices[split:], indices[:split]\n",
        "\n",
        "# define the sampler\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "test_sampler = SubsetRandomSampler(test_idx)\n",
        "\n",
        "# prepare loaders\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_data, batch_size=batch_size,\n",
        "    sampler=train_sampler)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_data, batch_size=batch_size,\n",
        "    sampler=test_sampler)\n",
        "\n",
        "print(\"Train dataloader:{}\".format(len(train_loader)))\n",
        "print(\"Test dataloader:{}\".format(len(test_loader)))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataloader:79\n",
            "Test dataloader:20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6cZQ_9hMiQO"
      },
      "source": [
        "class DeepNeuralNetworkModel(nn.Module):\n",
        "    def __init__(self, input_size, num_classes, num_hidden):\n",
        "        super().__init__()\n",
        "        ### 1st hidden layer: 784 --> 100\n",
        "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
        "        ### Non-linearity in 1st hidden layer\n",
        "        self.celu_1 = nn.CELU()\n",
        "\n",
        "        ### 2nd hidden layer: 100 --> 100\n",
        "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 2nd hidden layer\n",
        "        self.celu_2 = nn.CELU()\n",
        "        \n",
        "        ### 3rd hidden layer: 100 --> 100\n",
        "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 3rd hidden layer\n",
        "        self.celu_3 = nn.CELU()\n",
        "        \n",
        "        ### 4th hidden layer: 100 --> 100\n",
        "        self.linear_4 = nn.Linear(num_hidden, num_hidden)\n",
        "        ### Non-linearity in 4th hidden layer\n",
        "        self.celu_4 = nn.CELU()\n",
        "\n",
        "        ### Output layer: 100 --> 10\n",
        "        self.linear_out = nn.Linear(num_hidden, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        ### 1st hidden layer\n",
        "        out  = self.linear_1(x)\n",
        "        ### Non-linearity in 1st hidden layer\n",
        "        out = self.celu_1(out)\n",
        "        \n",
        "        ### 2nd hidden layer\n",
        "        out  = self.linear_2(out)\n",
        "        ### Non-linearity in 2nd hidden layer\n",
        "        out = self.celu_2(out)\n",
        "        \n",
        "        ### 3rd hidden layer\n",
        "        out  = self.linear_3(out)\n",
        "        ### Non-linearity in 3rd hidden layer\n",
        "        out = self.celu_3(out)\n",
        "        \n",
        "        ### 4th hidden layer\n",
        "        out  = self.linear_4(out)\n",
        "        ### Non-linearity in 3rd hidden layer\n",
        "        out = self.celu_4(out)\n",
        "        \n",
        "        # Linear layer (output)\n",
        "        probas  = self.linear_out(out)\n",
        "        return probas"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DMQl2l7Mjpk",
        "outputId": "d0870b8b-6a84-4f19-d3e5-c7e2b88a3200"
      },
      "source": [
        "# INSTANTIATE MODEL CLASS\n",
        "model = DeepNeuralNetworkModel(input_size = input_dim,\n",
        "                               num_classes = output_dim,\n",
        "                               num_hidden = num_hidden\n",
        "                              )\n",
        "# To enable GPU\n",
        "model.to(device)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeepNeuralNetworkModel(\n",
              "  (linear_1): Linear(in_features=784, out_features=100, bias=True)\n",
              "  (celu_1): CELU(alpha=1.0)\n",
              "  (linear_2): Linear(in_features=100, out_features=100, bias=True)\n",
              "  (celu_2): CELU(alpha=1.0)\n",
              "  (linear_3): Linear(in_features=100, out_features=100, bias=True)\n",
              "  (celu_3): CELU(alpha=1.0)\n",
              "  (linear_4): Linear(in_features=100, out_features=100, bias=True)\n",
              "  (celu_4): CELU(alpha=1.0)\n",
              "  (linear_out): Linear(in_features=100, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-NOhVbjSN95",
        "outputId": "f129f7dd-5bc6-492b-e241-4f6752d0895a"
      },
      "source": [
        "# INSTANTIATE LOSS & OPTIMIZER CLASS\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "iteration_loss = []\n",
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        images = images.view(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Clear gradients w.r.t. parameters\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass to get output/logits\n",
        "        outputs = model(images) \n",
        "\n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Getting gradients w.r.t. parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        iter += 1\n",
        "\n",
        "        if iter % 500 == 0:\n",
        "            # Calculate Accuracy         \n",
        "            correct = 0\n",
        "            total = 0\n",
        "            # Iterate through test dataset\n",
        "            for images, labels in test_loader:\n",
        "               \n",
        "                images = images.view(-1, 28*28).to(device)\n",
        "\n",
        "                # Forward pass only to get logits/output\n",
        "                outputs = model(images)\n",
        "\n",
        "                # Get predictions from the maximum value\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "                # Total number of labels\n",
        "                total += labels.size(0)\n",
        "\n",
        "\n",
        "                # Total correct predictions\n",
        "                if torch.cuda.is_available():\n",
        "                    correct += (predicted.cpu() == labels.cpu()).sum() \n",
        "                else:\n",
        "                    correct += (predicted == labels).sum()\n",
        "\n",
        "            accuracy = 100 * correct.item() / total\n",
        "\n",
        "            # Print Loss\n",
        "            iteration_loss.append(loss.item())\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 500. Loss: 1.009032964706421. Accuracy: 60.736040609137056\n",
            "Iteration: 1000. Loss: 0.9819592833518982. Accuracy: 72.81725888324873\n",
            "Iteration: 1500. Loss: 0.6968532800674438. Accuracy: 74.8730964467005\n"
          ]
        }
      ]
    }
  ]
}